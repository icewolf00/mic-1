{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n      //<![CDATA[\\n      var axel = Math.random() + \"\";\\n      var a = axel * 10000000000000;\\n      document.write(\\'<iframe src=\"https://2542116.fls.doubleclick.net/activityi;src=2542116;type=gblog;cat=googl0;ord=ord=\\' + a + \\'?\" width=\"1\" height=\"1\" frameborder=\"0\" style=\"display:none\"></iframe>\\');\\n      //]]>\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Blog\\n          \\n\\n\\n\\nThe latest news from Google AI\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe Google Brain Team — Looking Back on 2017 (Part 2 of 2)\\n\\n\\n\\n\\n\\nFriday, January 12, 2018\\n\\n\\n\\n\\n\\n\\n                          <span class=\"byline-author\">Posted by Jeff Dean, Google Senior Fellow, on behalf of the entire Google Brain Team</span><br />\\n<br />\\nThe <a href=\"//g.co/brain\">Google Brain team</a> works to advance the state of the art in artificial intelligence by research and systems engineering, as one part of the overall <a href=\"https://ai.google/\">Google AI</a> effort.  In <a href=\"https://ai.googleblog.com/2018/01/the-google-brain-team-looking-back-on.html\">Part 1 of this blog post</a>, we shared some of our work in 2017 related to our broader research, from designing new machine learning algorithms and techniques to understanding them, as well as sharing data, software, and hardware with the community. In this post, we&#8217;ll dive into the research we do in some specific domains such as healthcare, robotics, creativity, fairness and inclusion, as well as share a little more about us.<br />\\n<br />\\n<b>Healthcare</b><br />\\nWe feel there is enormous potential for the application of machine learning techniques to healthcare.  We are doing work across many different kinds of problems, including <a href=\"https://research.googleblog.com/2017/03/assisting-pathologists-in-detecting.html\">assisting pathologists in detecting cancer</a>, <a href=\"https://research.googleblog.com/2017/11/understanding-medical-conversations.html\">understanding medical conversations</a> to assist doctors and patients, and using machine learning to tackle a wide variety of problems in genomics, including an open-source release of a <a href=\"https://research.googleblog.com/2017/12/deepvariant-highly-accurate-genomes.html\">highly accurate variant calling system based on deep learning</a>.  <br />\\n<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody>\\n<tr><td style=\"text-align: center;\"><a href=\"https://research.googleblog.com/2017/03/assisting-pathologists-in-detecting.html\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"812\" data-original-width=\"1326\" height=\"390\" src=\"https://1.bp.blogspot.com/-TrFdtDyPH-0/Wlf4L-Mk0CI/AAAAAAAACVE/h1DHy_qepI0iGydt_Lc2sM69OQxr3RVHACLcBGAs/s640/image2.png\" width=\"640\" /></a></td></tr>\\n<tr><td class=\"tr-caption\" style=\"text-align: center;\">A lymph node biopsy, where <a href=\"https://research.googleblog.com/2017/03/assisting-pathologists-in-detecting.html\">our algorithm correctly identifies the tumor</a> and not the benign macrophage.</td></tr>\\n</tbody></table>\\nWe have continued our work on early detection of diabetic retinopathy (DR) and macular edema, building on the <a href=\"https://jamanetwork.com/journals/jama/article-abstract/2588763\">research paper</a> we published December 2016 in the Journal of the American Medical Association (<a href=\"https://jamanetwork.com/journals/jama\">JAMA</a>).  In 2017, we moved this project from research project to actual clinical impact.  We partnered with <a href=\"https://verily.com/\">Verily</a> (a life sciences company within Alphabet) to guide this work through the regulatory process, and together we are incorporating this technology into <a href=\"http://www.nikon.com/news/2016/1227_01.htm\">Nikon\\'s line of Optos ophthalmology cameras</a>.  In addition, we are working to deploy this system in India, where there is a shortage of 127,000 eye doctors and as a result, almost half of patients are diagnosed too late &#8212; after the disease has already caused vision loss. As a part of a pilot, we&#8217;ve launched this system to help graders at <a href=\"https://factordaily.com/news/google-india-aravind-eye-hospital-ai-diabetic-retinopathy/\">Aravind Eye Hospitals</a> to better diagnose diabetic eye disease. We are also working with our partners to understand the human factors affecting diabetic eye care, from ethnographic studies of patients and healthcare providers, to investigations on how eye care clinicians interact with the AI-enabled system.<br />\\n<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody>\\n<tr><td style=\"text-align: center;\"><a href=\"https://2.bp.blogspot.com/-TJ_QlzQ0hhs/Wlf4nReumNI/AAAAAAAACVI/BcQiAQ_2sI4Az4-v767a4pT9VNU6KN6xQCLcBGAs/s1600/2.png\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"825\" data-original-width=\"655\" height=\"640\" src=\"https://2.bp.blogspot.com/-TJ_QlzQ0hhs/Wlf4nReumNI/AAAAAAAACVI/BcQiAQ_2sI4Az4-v767a4pT9VNU6KN6xQCLcBGAs/s640/2.png\" width=\"507\" /></a></td></tr>\\n<tr><td class=\"tr-caption\" style=\"text-align: center;\">First patient screened (top) and Iniya Paramasivam, a trained grader, viewing the output of the system (bottom).</td></tr>\\n</tbody></table>\\nWe have also teamed up with researchers at leading healthcare organizations and medical centers including <a href=\"https://stanfordhealthcare.org/\">Stanford</a>, <a href=\"https://www.ucsfhealth.org/\">UCSF</a>, and <a href=\"http://www.uchospitals.edu/index.shtml\">University of Chicago</a> to demonstrate the effectiveness of using <a href=\"https://blog.google/topics/machine-learning/partnering-machine-learning-healthcare/\">machine learning to predict medical outcomes from de-identified medical records</a> (i.e. given the current state of a patient, we believe we can predict the future for a patient by learning from millions of other patients&#8217; journeys, as a way of helping healthcare professionals make better decisions).  We&#8217;re very excited about this avenue of work and we look to forward to telling you more about it in 2018. <br />\\n<br />\\n<b>Robotics</b><br />\\nOur long-term goal in robotics is to design learning algorithms to allow robots to operate in messy, real-world environments and to quickly acquire new skills and capabilities via learning, rather than the carefully-controlled conditions and the small set of hand-programmed tasks that characterize today&#8217;s robots. One thrust of our research is on developing techniques for physical robots to use their own experience and those of other robots to build new skills and capabilities, pooling the shared experiences in order to learn collectively.  We are also exploring ways in which we can combine <a href=\"https://research.googleblog.com/2017/10/closing-simulation-to-reality-gap-for.html\">computer-based simulations of robotic tasks with physical robotic experience</a> to learn new tasks more rapidly.  While the physics of the simulator don&#8217;t entirely match up with the real world, we have observed that for robotics, simulated experience plus a small amount of real-world experience gives significantly better results than even large amounts of real-world experience on its own.<br />\\n<br />\\nIn addition to real-world robotic experience and simulated robotic environments, we have <a href=\"https://research.googleblog.com/2017/07/teaching-robots-to-understand-semantic.html\">developed robotic learning algorithms that can learn by observing human demonstrations</a> of desired behaviors, and believe that this imitation learning approach is a highly promising way of imparting new abilities to robots very quickly, without explicit programming or even explicit specification of the goal of an activity.  For example, below is a video of a robot learning to pour from a cup in just 15 minutes of real world experience by observing humans performing this task from different viewpoints and then trying to imitate the behavior.  As we might be with our own three-year-old child, we&#8217;re encouraged that it only spills a little!<br />\\n<div class=\"separator\" style=\"clear: both; text-align: center;\">\\n<iframe allowfullscreen=\"\" class=\"YOUTUBE-iframe-video\" data-thumbnail-src=\"https://i.ytimg.com/vi/b1UTUQpxPSY/0.jpg\" frameborder=\"0\" height=\"360\" src=\"https://www.youtube.com/embed/b1UTUQpxPSY?rel=0&amp;start=116&amp;end=149;feature=player_embedded\" width=\"640\"></iframe></div>\\n<br />\\nWe also co-organized and hosted the first occurrence of the new <a href=\"http://www.robot-learning.org/\">Conference on Robot Learning</a> (CoRL) in November to bring together researchers working at the intersection of machine learning and robotics. The <a href=\"https://research.googleblog.com/2017/12/a-summary-of-first-conference-on-robot.html\">summary of the event</a> contains more information, and we look forward to next year&#8217;s occurrence of the conference in Zürich.<br />\\n<br />\\n<b>Basic Science</b><br />\\nWe are also excited about the long term potential of using machine learning to help solve important problems in science. Last year, we utilized neural networks for <a href=\"https://research.googleblog.com/2017/04/predicting-properties-of-molecules-with.html\">predicting molecular properties</a> in quantum chemistry, <a href=\"https://www.blog.google/topics/machine-learning/hunting-planets-machine-learning/\">finding new exoplanets</a> in astronomical datasets, earthquake aftershock prediction, and used <a href=\"https://arxiv.org/abs/1701.06972\">deep learning to guide automated proof systems</a>.<br />\\n<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody>\\n<tr><td style=\"text-align: center;\"><a href=\"https://arxiv.org/abs/1704.01212\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"235\" data-original-width=\"389\" height=\"241\" src=\"https://2.bp.blogspot.com/-O-fwquqFsgg/Wlf5EMe0A2I/AAAAAAAACVU/u-HSdvnWYbwhR7GJcTwLsE7IpdcuzWJbgCLcBGAs/s400/image1.png\" width=\"400\" /></a></td></tr>\\n<tr><td class=\"tr-caption\" style=\"text-align: center;\"><a href=\"https://research.googleblog.com/2017/04/predicting-properties-of-molecules-with.html\">A Message Passing Neural Network predicts quantum properties of an organic molecule</a></td></tr>\\n</tbody></table>\\n<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody>\\n<tr><td style=\"text-align: center;\"><a href=\"https://www.blog.google/topics/machine-learning/hunting-planets-machine-learning/\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"449\" data-original-width=\"904\" height=\"197\" src=\"https://3.bp.blogspot.com/-3Sv9BduvARE/Wlf5YBWvnzI/AAAAAAAACVY/8ypa7bIEPFUdcSS8uNfDi5Zrd8hATuf9gCLcBGAs/s400/image9.png\" width=\"400\" /></a></td></tr>\\n<tr><td class=\"tr-caption\" style=\"text-align: center;\"><a href=\"https://www.blog.google/topics/machine-learning/hunting-planets-machine-learning/\">Finding a new exoplanet</a>: observing brightness of stars when planets block their light.&nbsp;</td></tr>\\n</tbody></table>\\n<b>Creativity</b><br />\\nWe&#8217;re very interested in how to leverage machine learning as a tool to assist people in creative endeavors.  This year, we created an <a href=\"https://experiments.withgoogle.com/ai/ai-duet/view/\">AI piano duet tool</a>, helped YouTube musician Andrew Huang <a href=\"https://www.youtube.com/watch?v=AaALLWQmCdI&amp;feature=youtu.be\">create new music</a> (see also the behind the scenes video with <a href=\"https://www.youtube.com/watch?v=BOoSy-Pg8is\">Nat &amp; Friends</a>), and showed <a href=\"https://research.googleblog.com/2017/04/teaching-machines-to-draw.html\">how to teach machines to draw</a>.  <br />\\n<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody>\\n<tr><td style=\"text-align: center;\"><a href=\"https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"360\" data-original-width=\"640\" height=\"360\" src=\"https://1.bp.blogspot.com/-Z3R4BkRw8qg/Wlf5wUmckII/AAAAAAAACVg/PU5D0MsR_tY8YKyr00sHMGrxlrjErtg1wCLcBGAs/s640/image3.gif\" width=\"640\" /></a></td></tr>\\n<tr><td class=\"tr-caption\" style=\"text-align: center;\">A garden drawn by the <a href=\"https://research.googleblog.com/2017/04/teaching-machines-to-draw.html\">SketchRNN model</a>; an interactive demo is <a href=\"https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html\">available</a>.</td></tr>\\n</tbody></table>\\nWe also demonstrated <a href=\"https://nips.cc/Conferences/2017/Schedule?showEvent=9762\">how to control deep generative models running in the browser to create new music</a>. This work won the <a href=\"https://nips.cc/Conferences/2017/Awards\">NIPS 2017 Best Demo Award</a>, making this the second year in a row that members of the Brain team&#8217;s <a href=\"http://magenta.tensorflow.org/\">Magenta project</a> have won this award, following on our receipt of the <a href=\"https://nips.cc/Conferences/2016/Awards\">NIPS 2016 Best Demo Award</a> for <a href=\"https://nips.cc/Conferences/2016/Schedule?showEvent=6307\">Interactive musical improvisation with Magenta</a>. In the YouTube video below, you can listen to one part of the demo, the <a href=\"https://colab.research.google.com/notebook#fileId=/v2/external/notebooks/magenta/music_vae/music_vae.ipynb\">MusicVAE</a> variational autoencoder model morphing smoothly from one melody to another. <br />\\n<div class=\"separator\" style=\"clear: both; text-align: center;\">\\n<iframe allowfullscreen=\"\" class=\"YOUTUBE-iframe-video\" data-thumbnail-src=\"https://i.ytimg.com/vi/jNiES3pdrU4/0.jpg\" frameborder=\"0\" height=\"360\" src=\"https://www.youtube.com/embed/jNiES3pdrU4?rel=0&amp;feature=player_embedded\" width=\"640\"></iframe></div>\\n<b>People + AI Research (PAIR) Initiative</b><br />\\nAdvances in machine learning offer entirely new possibilities for how people might interact with computers.  At the same time, it&#8217;s critical to make sure that society can broadly benefit from the technology we&#8217;re building.  We see these opportunities and challenges as an urgent matter, and teamed up with a number of people throughout Google to create the <a href=\"https://ai.google/pair\">People + AI Research (PAIR)</a> initiative.<br />\\n<br />\\nPAIR&#8217;s goal is to study and design the most effective ways for people to interact with AI systems.  We kicked off the initiative with a <a href=\"https://sites.google.com/corp/view/pair-symposium2017/home\">public symposium</a> bringing together academics and practitioners across disciplines ranging from computer science, design, and even art.  PAIR works on a wide range of topics, some of which we&#8217;ve already mentioned: helping researchers understand ML systems through work on interpretability and expanding the community of developers with <a href=\"http://deeplearnjs.org/\">deeplearn.js</a>.  Another example of our human-centered approach to ML engineering is the launch of <a href=\"https://pair-code.github.io/facets/\">Facets</a>, a tool for visualizing and understanding training datasets.<br />\\n<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody>\\n<tr><td style=\"text-align: center;\"><a href=\"https://pair-code.github.io/facets/\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"505\" data-original-width=\"620\" height=\"520\" src=\"https://1.bp.blogspot.com/-okXsVBEhLws/Wlf6S3qliHI/AAAAAAAACVs/ddGvwr3jKLw9bTuUqlDuiu2Z4k_ABPQjgCLcBGAs/s640/image4.gif\" width=\"640\" /></a></td></tr>\\n<tr><td class=\"tr-caption\" style=\"text-align: center;\"><a href=\"https://pair-code.github.io/facets/\">Facets</a> provides insights into your training datasets.</td></tr>\\n</tbody></table>\\n<b>Fairness and Inclusion in Machine Learning</b><br />\\nAs ML plays an increasing role in technology, considerations of inclusivity and fairness grow in importance. The Brain team and <a href=\"https://ai.google/pair\">PAIR</a> have been working hard to make progress in these areas. We&#8217;ve published on <a href=\"https://arxiv.org/pdf/1706.02744.pdf\">how to avoid discrimination in ML systems</a> via causal reasoning, the importance of <a href=\"https://arxiv.org/abs/1711.08536\">geodiversity in open datasets</a>, and posted <a href=\"https://research.googleblog.com/2017/08/exploring-and-visualizing-open-global.html\">an analysis of an open dataset to understand diversity and cultural differences</a>.  We&#8217;ve also been working closely with the <a href=\"https://www.partnershiponai.org/\">Partnership on AI</a>, a cross-industry initiative, to help make sure that fairness and inclusion are promoted as goals for all ML practitioners.<br />\\n<table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody>\\n<tr><td style=\"text-align: center;\"><a href=\"https://4.bp.blogspot.com/-YXh56TsSCTA/WljlmZLVg9I/AAAAAAAACV8/TbYNJUZ0QfMg_7qyKni3u-HjJ18qyA69ACLcBGAs/s1600/fig.png\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"1002\" data-original-width=\"1600\" height=\"400\" src=\"https://4.bp.blogspot.com/-YXh56TsSCTA/WljlmZLVg9I/AAAAAAAACV8/TbYNJUZ0QfMg_7qyKni3u-HjJ18qyA69ACLcBGAs/s640/fig.png\" width=\"640\" /></a></td></tr>\\n<tr><td class=\"tr-caption\" style=\"text-align: center;\"><br />\\n<a href=\"https://research.googleblog.com/2017/08/exploring-and-visualizing-open-global.html\">Cultural differences</a> can surface in training data even in objects as &#8220;universal&#8221; as chairs, as observed in these doodle patterns on the left. The chart on the right shows how we uncovered <a href=\"https://arxiv.org/abs/1711.08536\">geo-location biases</a> in standard open source data sets such as ImageNet. Undetected or uncorrected, such biases may strongly influence model behavior.</td></tr>\\n</tbody></table>\\nWe made this video in collaboration with our colleagues at Google Creative Lab as a non-technical introduction to some of the issues in this area.<br />\\n<div class=\"separator\" style=\"clear: both; text-align: center;\">\\n<iframe allowfullscreen=\"\" class=\"YOUTUBE-iframe-video\" data-thumbnail-src=\"https://i.ytimg.com/vi/59bMh59JQDo/0.jpg\" frameborder=\"0\" height=\"360\" src=\"https://www.youtube.com/embed/59bMh59JQDo?rel=0&amp;feature=player_embedded\" width=\"640\"></iframe></div>\\n<b>Our Culture</b><br />\\nOne aspect of our group&#8217;s research culture is to empower researchers and engineers to tackle the basic research problems that they view as most important.  In September, <a href=\"https://research.googleblog.com/2017/09/the-google-brain-teams-approach-to.html\">we posted about our general approach to conducting research</a>.  Educating and mentoring young researchers is something we do through our research efforts.  Our group hosted over 100 interns last year, and roughly 25% of our research publications in 2017 have intern co-authors.  In 2016, we started the Google Brain Residency, a program for mentoring people who wanted to learn to do machine learning research.  In the inaugural year (June 2016 to May 2017), 27 residents joined our group, and we posted updates about the first year of the program in <a href=\"https://research.googleblog.com/2017/01/google-brain-residency-program-7-months_5.html\">halfway through</a> and <a href=\"https://research.googleblog.com/2017/07/the-google-brain-residency-program-one.html\">just after the end</a> highlighting the research accomplishments of the residents.  Many of the residents in the first year of the program have stayed on in our group as full-time researchers and research engineers, and most of those that did not have gone on to Ph.D. programs at top machine learning graduate programs like Berkeley, CMU, Stanford, NYU and Toronto.  In July, 2017, we also welcomed our second cohort of 35 residents, who will be with us until July, 2018, and they&#8217;ve <a href=\"https://www.blog.google/topics/machine-learning/ai-resident-work-suhani-vora-and-her-work-genomics/\">already done some exciting research</a> and <a href=\"https://research.google.com/pubs/AIResidency.html\">published at numerous research venues</a>.  We&#8217;ve now broadened the program to include many other research groups across Google and renamed it the <a href=\"//g.co/airesidency\">Google AI Residency program</a> (the application deadline for this year\\'s program has just passed; look for information about next year\\'s program at <a href=\"//g.co/airesidency/apply\">g.co/airesidency/apply</a>).<br />\\n<br />\\nOur work in 2017 spanned more than we&#8217;ve highlighted on in this two-part blog post.  We believe in publishing our work in top research venues, and last year our group published 140 papers, including more than 60 at <a href=\"https://research.googleblog.com/2017/04/research-at-google-and-iclr-2017.html\">ICLR</a>, <a href=\"https://research.googleblog.com/2017/08/google-at-icml-2017.html\">ICML</a>, and <a href=\"https://research.googleblog.com/2017/12/google-at-nips-2017.html\">NIPS</a>.  To learn more about our work, you can peruse our <a href=\"https://research.google.com/pubs/BrainTeam.html\">research papers</a>.  <br />\\n<br />\\nYou can also meet some of our team members in this <a href=\"https://www.youtube.com/watch?v=rsN690cfWsM&amp;t=4s\">video</a>, or read our responses to our second <a href=\"https://www.reddit.com/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/\">Ask Me Anything (AMA)</a> post on <a href=\"http://reddit.com/r/MachineLearning\">r/MachineLearning</a> (and check out the <a href=\"https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/\">2016&#8217;s AMA</a>, too).<br />\\n<br />\\nThe Google Brain team is becoming more spread out, with team members across North America and Europe.  If the work we&#8217;re doing sounds interesting and you&#8217;d like to join us, you can see our open positions and apply for internships, the AI Residency program, visiting faculty, or full-time research or engineering roles using the links at the bottom of <a href=\"//g.co/brain\">g.co/brain</a>. You can also follow our work throughout 2018 here on the Google Research blog, or on Twitter at <a href=\"https://twitter.com/googleresearch\">@GoogleResearch</a>.  You can also follow my personal account at <a href=\"https://twitter.com/JeffDean\">@JeffDean</a>.<br />\\n<br />\\nThanks for reading!\\n<span itemprop=\\'author\\' itemscope=\\'itemscope\\' itemtype=\\'http://schema.org/Person\\'>\\n  <meta content=\\'https://plus.google.com/116899029375914044550\\' itemprop=\\'url\\'/>\\n</span>\\n                        \\n\\nPosted by Jeff Dean, Google Senior Fellow, on behalf of the entire Google Brain Team\\n\\nThe Google Brain team works to advance the state of the art in artificial intelligence by research and systems engineering, as one part of the overall Google AI effort.  In Part 1 of this blog post, we shared some of our work in 2017 related to our broader research, from designing new machine learning algorithms and techniques to understanding them, as well as sharing data, software, and hardware with the community. In this post, we’ll dive into the research we do in some specific domains such as healthcare, robotics, creativity, fairness and inclusion, as well as share a little more about us.\\n\\nHealthcare\\nWe feel there is enormous potential for the application of machine learning techniques to healthcare.  We are doing work across many different kinds of problems, including assisting pathologists in detecting cancer, understanding medical conversations to assist doctors and patients, and using machine learning to tackle a wide variety of problems in genomics, including an open-source release of a highly accurate variant calling system based on deep learning.  \\n\\n\\nA lymph node biopsy, where our algorithm correctly identifies the tumor and not the benign macrophage.\\n\\nWe have continued our work on early detection of diabetic retinopathy (DR) and macular edema, building on the research paper we published December 2016 in the Journal of the American Medical Association (JAMA).  In 2017, we moved this project from research project to actual clinical impact.  We partnered with Verily (a life sciences company within Alphabet) to guide this work through the regulatory process, and together we are incorporating this technology into Nikon\\'s line of Optos ophthalmology cameras.  In addition, we are working to deploy this system in India, where there is a shortage of 127,000 eye doctors and as a result, almost half of patients are diagnosed too late — after the disease has already caused vision loss. As a part of a pilot, we’ve launched this system to help graders at Aravind Eye Hospitals to better diagnose diabetic eye disease. We are also working with our partners to understand the human factors affecting diabetic eye care, from ethnographic studies of patients and healthcare providers, to investigations on how eye care clinicians interact with the AI-enabled system.\\n\\n\\nFirst patient screened (top) and Iniya Paramasivam, a trained grader, viewing the output of the system (bottom).\\n\\nWe have also teamed up with researchers at leading healthcare organizations and medical centers including Stanford, UCSF, and University of Chicago to demonstrate the effectiveness of using machine learning to predict medical outcomes from de-identified medical records (i.e. given the current state of a patient, we believe we can predict the future for a patient by learning from millions of other patients’ journeys, as a way of helping healthcare professionals make better decisions).  We’re very excited about this avenue of work and we look to forward to telling you more about it in 2018. \\n\\nRobotics\\nOur long-term goal in robotics is to design learning algorithms to allow robots to operate in messy, real-world environments and to quickly acquire new skills and capabilities via learning, rather than the carefully-controlled conditions and the small set of hand-programmed tasks that characterize today’s robots. One thrust of our research is on developing techniques for physical robots to use their own experience and those of other robots to build new skills and capabilities, pooling the shared experiences in order to learn collectively.  We are also exploring ways in which we can combine computer-based simulations of robotic tasks with physical robotic experience to learn new tasks more rapidly.  While the physics of the simulator don’t entirely match up with the real world, we have observed that for robotics, simulated experience plus a small amount of real-world experience gives significantly better results than even large amounts of real-world experience on its own.\\n\\nIn addition to real-world robotic experience and simulated robotic environments, we have developed robotic learning algorithms that can learn by observing human demonstrations of desired behaviors, and believe that this imitation learning approach is a highly promising way of imparting new abilities to robots very quickly, without explicit programming or even explicit specification of the goal of an activity.  For example, below is a video of a robot learning to pour from a cup in just 15 minutes of real world experience by observing humans performing this task from different viewpoints and then trying to imitate the behavior.  As we might be with our own three-year-old child, we’re encouraged that it only spills a little!\\n\\n\\n\\nWe also co-organized and hosted the first occurrence of the new Conference on Robot Learning (CoRL) in November to bring together researchers working at the intersection of machine learning and robotics. The summary of the event contains more information, and we look forward to next year’s occurrence of the conference in Zürich.\\n\\nBasic Science\\nWe are also excited about the long term potential of using machine learning to help solve important problems in science. Last year, we utilized neural networks for predicting molecular properties in quantum chemistry, finding new exoplanets in astronomical datasets, earthquake aftershock prediction, and used deep learning to guide automated proof systems.\\n\\n\\nA Message Passing Neural Network predicts quantum properties of an organic molecule\\n\\n\\n\\nFinding a new exoplanet: observing brightness of stars when planets block their light.\\xa0\\n\\nCreativity\\nWe’re very interested in how to leverage machine learning as a tool to assist people in creative endeavors.  This year, we created an AI piano duet tool, helped YouTube musician Andrew Huang create new music (see also the behind the scenes video with Nat & Friends), and showed how to teach machines to draw.  \\n\\n\\nA garden drawn by the SketchRNN model; an interactive demo is available.\\n\\nWe also demonstrated how to control deep generative models running in the browser to create new music. This work won the NIPS 2017 Best Demo Award, making this the second year in a row that members of the Brain team’s Magenta project have won this award, following on our receipt of the NIPS 2016 Best Demo Award for Interactive musical improvisation with Magenta. In the YouTube video below, you can listen to one part of the demo, the MusicVAE variational autoencoder model morphing smoothly from one melody to another. \\n\\n\\nPeople + AI Research (PAIR) Initiative\\nAdvances in machine learning offer entirely new possibilities for how people might interact with computers.  At the same time, it’s critical to make sure that society can broadly benefit from the technology we’re building.  We see these opportunities and challenges as an urgent matter, and teamed up with a number of people throughout Google to create the People + AI Research (PAIR) initiative.\\n\\nPAIR’s goal is to study and design the most effective ways for people to interact with AI systems.  We kicked off the initiative with a public symposium bringing together academics and practitioners across disciplines ranging from computer science, design, and even art.  PAIR works on a wide range of topics, some of which we’ve already mentioned: helping researchers understand ML systems through work on interpretability and expanding the community of developers with deeplearn.js.  Another example of our human-centered approach to ML engineering is the launch of Facets, a tool for visualizing and understanding training datasets.\\n\\n\\nFacets provides insights into your training datasets.\\n\\nFairness and Inclusion in Machine Learning\\nAs ML plays an increasing role in technology, considerations of inclusivity and fairness grow in importance. The Brain team and PAIR have been working hard to make progress in these areas. We’ve published on how to avoid discrimination in ML systems via causal reasoning, the importance of geodiversity in open datasets, and posted an analysis of an open dataset to understand diversity and cultural differences.  We’ve also been working closely with the Partnership on AI, a cross-industry initiative, to help make sure that fairness and inclusion are promoted as goals for all ML practitioners.\\n\\n\\n\\nCultural differences can surface in training data even in objects as “universal” as chairs, as observed in these doodle patterns on the left. The chart on the right shows how we uncovered geo-location biases in standard open source data sets such as ImageNet. Undetected or uncorrected, such biases may strongly influence model behavior.\\n\\nWe made this video in collaboration with our colleagues at Google Creative Lab as a non-technical introduction to some of the issues in this area.\\n\\n\\nOur Culture\\nOne aspect of our group’s research culture is to empower researchers and engineers to tackle the basic research problems that they view as most important.  In September, we posted about our general approach to conducting research.  Educating and mentoring young researchers is something we do through our research efforts.  Our group hosted over 100 interns last year, and roughly 25% of our research publications in 2017 have intern co-authors.  In 2016, we started the Google Brain Residency, a program for mentoring people who wanted to learn to do machine learning research.  In the inaugural year (June 2016 to May 2017), 27 residents joined our group, and we posted updates about the first year of the program in halfway through and just after the end highlighting the research accomplishments of the residents.  Many of the residents in the first year of the program have stayed on in our group as full-time researchers and research engineers, and most of those that did not have gone on to Ph.D. programs at top machine learning graduate programs like Berkeley, CMU, Stanford, NYU and Toronto.  In July, 2017, we also welcomed our second cohort of 35 residents, who will be with us until July, 2018, and they’ve already done some exciting research and published at numerous research venues.  We’ve now broadened the program to include many other research groups across Google and renamed it the Google AI Residency program (the application deadline for this year\\'s program has just passed; look for information about next year\\'s program at g.co/airesidency/apply).\\n\\nOur work in 2017 spanned more than we’ve highlighted on in this two-part blog post.  We believe in publishing our work in top research venues, and last year our group published 140 papers, including more than 60 at ICLR, ICML, and NIPS.  To learn more about our work, you can peruse our research papers.  \\n\\nYou can also meet some of our team members in this video, or read our responses to our second Ask Me Anything (AMA) post on r/MachineLearning (and check out the 2016’s AMA, too).\\n\\nThe Google Brain team is becoming more spread out, with team members across North America and Europe.  If the work we’re doing sounds interesting and you’d like to join us, you can see our open positions and apply for internships, the AI Residency program, visiting faculty, or full-time research or engineering roles using the links at the bottom of g.co/brain. You can also follow our work throughout 2018 here on the Google Research blog, or on Twitter at @GoogleResearch.  You can also follow my personal account at @JeffDean.\\n\\nThanks for reading!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        Google\\n                      \\n\\n\\nLabels:\\n\\n\\n\\nDeep Learning\\n\\n\\n                                ,\\n                              \\n\\nGoogle Brain\\n\\n\\n                                ,\\n                              \\n\\nResearch\\n\\n\\n                                ,\\n                              \\n\\nTensorFlow\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                      \\ue88a\\n                    \\n\\n\\n\\n\\n                          \\ue5c4\\n                        \\n\\n\\n\\n\\n\\n                          \\ue5c8\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLabels\\n\\n\\n                      \\ue5c5\\n                    \\n\\n\\n\\n\\n\\naccessibility\\n\\n\\n\\n\\nACL\\n\\n\\n\\n\\nACM\\n\\n\\n\\n\\nAcoustic Modeling\\n\\n\\n\\n\\nAdaptive Data Analysis\\n\\n\\n\\n\\nads\\n\\n\\n\\n\\nadsense\\n\\n\\n\\n\\nadwords\\n\\n\\n\\n\\nAfrica\\n\\n\\n\\n\\nAI\\n\\n\\n\\n\\nAlgorithms\\n\\n\\n\\n\\nAndroid\\n\\n\\n\\n\\nAndroid Wear\\n\\n\\n\\n\\nAPI\\n\\n\\n\\n\\nApp Engine\\n\\n\\n\\n\\nApp Inventor\\n\\n\\n\\n\\nApril Fools\\n\\n\\n\\n\\nArt\\n\\n\\n\\n\\nAudio\\n\\n\\n\\n\\nAugmented Reality\\n\\n\\n\\n\\nAustralia\\n\\n\\n\\n\\nAutomatic Speech Recognition\\n\\n\\n\\n\\nAwards\\n\\n\\n\\n\\nCantonese\\n\\n\\n\\n\\nChemistry\\n\\n\\n\\n\\nChina\\n\\n\\n\\n\\nChrome\\n\\n\\n\\n\\nCloud Computing\\n\\n\\n\\n\\nCollaboration\\n\\n\\n\\n\\nComputational Imaging\\n\\n\\n\\n\\nComputational Photography\\n\\n\\n\\n\\nComputer Science\\n\\n\\n\\n\\nComputer Vision\\n\\n\\n\\n\\nconference\\n\\n\\n\\n\\nconferences\\n\\n\\n\\n\\nConservation\\n\\n\\n\\n\\ncorrelate\\n\\n\\n\\n\\nCourse Builder\\n\\n\\n\\n\\ncrowd-sourcing\\n\\n\\n\\n\\nCVPR\\n\\n\\n\\n\\nData Center\\n\\n\\n\\n\\nData Discovery\\n\\n\\n\\n\\ndata science\\n\\n\\n\\n\\ndatasets\\n\\n\\n\\n\\nDeep Learning\\n\\n\\n\\n\\nDeepDream\\n\\n\\n\\n\\nDeepMind\\n\\n\\n\\n\\ndistributed systems\\n\\n\\n\\n\\nDiversity\\n\\n\\n\\n\\nEarth Engine\\n\\n\\n\\n\\neconomics\\n\\n\\n\\n\\nEducation\\n\\n\\n\\n\\nElectronic Commerce and Algorithms\\n\\n\\n\\n\\nelectronics\\n\\n\\n\\n\\nEMEA\\n\\n\\n\\n\\nEMNLP\\n\\n\\n\\n\\nEncryption\\n\\n\\n\\n\\nentities\\n\\n\\n\\n\\nEntity Salience\\n\\n\\n\\n\\nEnvironment\\n\\n\\n\\n\\nEurope\\n\\n\\n\\n\\nExacycle\\n\\n\\n\\n\\nExpander\\n\\n\\n\\n\\nFaculty Institute\\n\\n\\n\\n\\nFaculty Summit\\n\\n\\n\\n\\nFlu Trends\\n\\n\\n\\n\\nFusion Tables\\n\\n\\n\\n\\ngamification\\n\\n\\n\\n\\nGboard\\n\\n\\n\\n\\nGmail\\n\\n\\n\\n\\nGoogle Accelerated Science\\n\\n\\n\\n\\nGoogle Books\\n\\n\\n\\n\\nGoogle Brain\\n\\n\\n\\n\\nGoogle Cloud Platform\\n\\n\\n\\n\\nGoogle Docs\\n\\n\\n\\n\\nGoogle Drive\\n\\n\\n\\n\\nGoogle Genomics\\n\\n\\n\\n\\nGoogle Maps\\n\\n\\n\\n\\nGoogle Photos\\n\\n\\n\\n\\nGoogle Play Apps\\n\\n\\n\\n\\nGoogle Science Fair\\n\\n\\n\\n\\nGoogle Sheets\\n\\n\\n\\n\\nGoogle Translate\\n\\n\\n\\n\\nGoogle Trips\\n\\n\\n\\n\\nGoogle Voice Search\\n\\n\\n\\n\\nGoogle+\\n\\n\\n\\n\\nGovernment\\n\\n\\n\\n\\ngrants\\n\\n\\n\\n\\nGraph\\n\\n\\n\\n\\nGraph Mining\\n\\n\\n\\n\\nHardware\\n\\n\\n\\n\\nHCI\\n\\n\\n\\n\\nHealth\\n\\n\\n\\n\\nHigh Dynamic Range Imaging\\n\\n\\n\\n\\nICLR\\n\\n\\n\\n\\nICML\\n\\n\\n\\n\\nICSE\\n\\n\\n\\n\\nImage Annotation\\n\\n\\n\\n\\nImage Classification\\n\\n\\n\\n\\nImage Processing\\n\\n\\n\\n\\nInbox\\n\\n\\n\\n\\nIndia\\n\\n\\n\\n\\nInformation Retrieval\\n\\n\\n\\n\\ninternationalization\\n\\n\\n\\n\\nInternet of Things\\n\\n\\n\\n\\nInterspeech\\n\\n\\n\\n\\nIPython\\n\\n\\n\\n\\nJournalism\\n\\n\\n\\n\\njsm\\n\\n\\n\\n\\njsm2011\\n\\n\\n\\n\\nK-12\\n\\n\\n\\n\\nKDD\\n\\n\\n\\n\\nKeyboard Input\\n\\n\\n\\n\\nKlingon\\n\\n\\n\\n\\nKorean\\n\\n\\n\\n\\nLabs\\n\\n\\n\\n\\nLinear Optimization\\n\\n\\n\\n\\nlocalization\\n\\n\\n\\n\\nLow-Light Photography\\n\\n\\n\\n\\nMachine Hearing\\n\\n\\n\\n\\nMachine Intelligence\\n\\n\\n\\n\\nMachine Learning\\n\\n\\n\\n\\nMachine Perception\\n\\n\\n\\n\\nMachine Translation\\n\\n\\n\\n\\nMagenta\\n\\n\\n\\n\\nMapReduce\\n\\n\\n\\n\\nmarket algorithms\\n\\n\\n\\n\\nMarket Research\\n\\n\\n\\n\\nMixed Reality\\n\\n\\n\\n\\nML\\n\\n\\n\\n\\nMOOC\\n\\n\\n\\n\\nMoore\\'s Law\\n\\n\\n\\n\\nMultimodal Learning\\n\\n\\n\\n\\nNAACL\\n\\n\\n\\n\\nNatural Language Processing\\n\\n\\n\\n\\nNatural Language Understanding\\n\\n\\n\\n\\nNetwork Management\\n\\n\\n\\n\\nNetworks\\n\\n\\n\\n\\nNeural Networks\\n\\n\\n\\n\\nNexus\\n\\n\\n\\n\\nNgram\\n\\n\\n\\n\\nNIPS\\n\\n\\n\\n\\nNLP\\n\\n\\n\\n\\nOn-device Learning\\n\\n\\n\\n\\nopen source\\n\\n\\n\\n\\noperating systems\\n\\n\\n\\n\\nOptical Character Recognition\\n\\n\\n\\n\\noptimization\\n\\n\\n\\n\\nosdi\\n\\n\\n\\n\\nosdi10\\n\\n\\n\\n\\npatents\\n\\n\\n\\n\\nPeer Review\\n\\n\\n\\n\\nph.d. fellowship\\n\\n\\n\\n\\nPhD Fellowship\\n\\n\\n\\n\\nPhotoScan\\n\\n\\n\\n\\nPhysics\\n\\n\\n\\n\\nPiLab\\n\\n\\n\\n\\nPixel\\n\\n\\n\\n\\nPolicy\\n\\n\\n\\n\\nProfessional Development\\n\\n\\n\\n\\nProposals\\n\\n\\n\\n\\nPublic Data Explorer\\n\\n\\n\\n\\npublication\\n\\n\\n\\n\\nPublications\\n\\n\\n\\n\\nQuantum AI\\n\\n\\n\\n\\nQuantum Computing\\n\\n\\n\\n\\nrenewable energy\\n\\n\\n\\n\\nResearch\\n\\n\\n\\n\\nResearch Awards\\n\\n\\n\\n\\nresource optimization\\n\\n\\n\\n\\nRobotics\\n\\n\\n\\n\\nschema.org\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nsearch ads\\n\\n\\n\\n\\nSecurity and Privacy\\n\\n\\n\\n\\nSemantic Models\\n\\n\\n\\n\\nSemi-supervised Learning\\n\\n\\n\\n\\nSIGCOMM\\n\\n\\n\\n\\nSIGMOD\\n\\n\\n\\n\\nSite Reliability Engineering\\n\\n\\n\\n\\nSocial Networks\\n\\n\\n\\n\\nSoftware\\n\\n\\n\\n\\nSpeech\\n\\n\\n\\n\\nSpeech Recognition\\n\\n\\n\\n\\nstatistics\\n\\n\\n\\n\\nStructured Data\\n\\n\\n\\n\\nStyle Transfer\\n\\n\\n\\n\\nSupervised Learning\\n\\n\\n\\n\\nSystems\\n\\n\\n\\n\\nTensorBoard\\n\\n\\n\\n\\nTensorFlow\\n\\n\\n\\n\\nTPU\\n\\n\\n\\n\\nTranslate\\n\\n\\n\\n\\ntrends\\n\\n\\n\\n\\nTTS\\n\\n\\n\\n\\nTV\\n\\n\\n\\n\\nUI\\n\\n\\n\\n\\nUniversity Relations\\n\\n\\n\\n\\nUNIX\\n\\n\\n\\n\\nUser Experience\\n\\n\\n\\n\\nvideo\\n\\n\\n\\n\\nVideo Analysis\\n\\n\\n\\n\\nVirtual Reality\\n\\n\\n\\n\\nVision Research\\n\\n\\n\\n\\nVisiting Faculty\\n\\n\\n\\n\\nVisualization\\n\\n\\n\\n\\nVLDB\\n\\n\\n\\n\\nVoice Search\\n\\n\\n\\n\\nWiki\\n\\n\\n\\n\\nwikipedia\\n\\n\\n\\n\\nWWW\\n\\n\\n\\n\\nYouTube\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                      \\ue2c7\\n                    \\n\\nArchive\\n\\n\\n                      \\ue5c5\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c7\\n                      \\n                      \\xa0\\n                      \\n\\n\\n\\n2018\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2017\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNov\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOct\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2016\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNov\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOct\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2015\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNov\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOct\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2014\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNov\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOct\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2013\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNov\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOct\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2012\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOct\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2011\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNov\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2010\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNov\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOct\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2009\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNov\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2008\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNov\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOct\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2007\\n\\n\\n\\n\\n\\n\\n\\nOct\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\ue5c5\\n                  \\n\\n\\n\\n\\n                        \\ue5c5\\n                      \\n                      \\xa0\\n                    \\n\\n\\n\\n2006\\n\\n\\n\\n\\n\\n\\n\\nDec\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNov\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSep\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAug\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJul\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApr\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMar\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFeed\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGoogleon\\n\\n\\n\\nFollow @googleai\\n     \\n      function sharingPopup (button) {\\n      var url = button.getAttribute(\"data-href\");\\n\\t    window.open(\\n url,\\'popUpWindow\\',\\'height=500,width=500,left=10,top=10,resizable=yes,scrollbars=yes,toolbar=yes,menubar=no,location=no,directories=no,status=yes\\');\\n          }\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGive us feedback in our Product Forums.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Google\\n            \\n\\n\\n\\n              Privacy\\n            \\n\\n\\n\\n              Terms\\n            \\n\\n\\n\\n\\n\\n      //<![CDATA[\\n      // Social sharing popups.\\n      var postEl = document.getElementsByClassName(\\'social-wrapper\\');\\n      var postCount = postEl.length;\\n      for(i=0; i<postCount;i++){\\n        postEl[i].addEventListener(\"click\", function(event){\\n          var postUrl = this.getAttribute(\"data-href\");\\n          window.open(\\n            postUrl,\\'popUpWindow\\',\\'height=500,width=500,left=10,top=10,resizable=yes,scrollbars=yes,toolbar=yes,menubar=no,location=no,directories=no,status=yes\\');\\n        });}\\n      //]]>\\n    \\n\\n      //<![CDATA[\\n      var BreakpointHandler = function() {\\n        this.initted = false;\\n        this.isHomePage = false;\\n        this.isMobile = false;\\n      };\\n      BreakpointHandler.prototype.finalizeSummary = function(summaryHtml, lastNode) {\\n        // Use $.trim for IE8 compatibility\\n        summaryHtml = $.trim(summaryHtml).replace(/(<br>|\\\\s)+$/,\\'\\');\\n        if (lastNode.nodeType == 3) {\\n          var lastChar = summaryHtml.slice(-1);\\n          if (!lastChar.match(/[.”\"?]/)) {\\n            if (!lastChar.match(/[A-Za-z]/)) {\\n              summaryHtml = summaryHtml.slice(0, -1);\\n            }\\n            summaryHtml += \\' ...\\';\\n          }\\n        } else if (lastNode.nodeType == 1 && (lastNode.nodeName == \\'I\\' || lastNode.nodeName == \\'A\\')) {\\n          summaryHtml += \\' ...\\';\\n        }\\n        return summaryHtml;\\n      };\\n      BreakpointHandler.prototype.generateSummaryFromContent = function(content, numWords) {\\n        var seenWords = 0;\\n        var summaryHtml = \\'\\';\\n        for (var i=0; i < content.childNodes.length; i++) {\\n          var node = content.childNodes[i];\\n          var nodeText;\\n          if (node.nodeType == 1) {\\n            if (node.hasAttribute(\\'data-about-pullquote\\')) {\\n              continue;\\n            }\\n            nodeText = node.textContent;\\n            if (nodeText === undefined) {\\n              // innerText for IE8\\n              nodeText = node.innerText;\\n            }\\n            if (node.nodeName == \\'DIV\\' || node.nodeName == \\'B\\') {\\n              // Don\\'t end early if we haven\\'t seen enough words.\\n              if (seenWords < 10) {\\n                continue;\\n              }\\n              if (i > 0) {\\n                summaryHtml = this.finalizeSummary(summaryHtml, content.childNodes[i-1]);\\n              }\\n              break;\\n            }\\n            summaryHtml += node.outerHTML;\\n          } else if (node.nodeType == 3) {\\n            nodeText = node.nodeValue;\\n            summaryHtml += nodeText + \\' \\';\\n          }\\n          var words = nodeText.match(/\\\\S+\\\\s*/g);\\n          if (!words) {\\n            continue;\\n          }\\n          var remain = numWords - seenWords;\\n          if (words.length >= remain) {\\n            summaryHtml = this.finalizeSummary(summaryHtml, node);\\n            break;\\n          }\\n          seenWords += words.length;\\n        }\\n        return summaryHtml;\\n      };\\n      BreakpointHandler.prototype.detect = function() {\\n        var match,\\n            pl     = /\\\\+/g,\\n            search = /([^&=]+)=?([^&]*)/g,\\n            decode = function (s) { return decodeURIComponent(s.replace(pl, \" \")); },\\n            query  = window.location.search.substring(1);\\n        var urlParams = {};\\n        while (match = search.exec(query))\\n          urlParams[decode(match[1])] = decode(match[2]);\\n        this.isListPage = $(\\'html\\').hasClass(\\'list-page\\');\\n        this.isMobile = urlParams[\\'m\\'] === \\'1\\';\\n        this.isHomePage = window.location.pathname == \\'/\\';\\n      };\\n      BreakpointHandler.prototype.initContent = function() {\\n        var self = this;\\n        $(\\'.post\\').each(function(index) {\\n          var body = $(this).children(\\'.post-body\\')[0];\\n          var content = $(body).children(\\'.post-content\\')[0];\\n          $(content).addClass(\\'post-original\\');\\n          var data = $(content).children(\\'script\\').html();\\n          data = self.rewriteForSSL(data);\\n          // If exists, extract specified editor\\'s preview.\\n          var match = data.match(/([\\\\s\\\\S]+?)<div data-is-preview.+?>([\\\\s\\\\S]+)<\\\\/div>/m);\\n          if (match) {\\n            data = match[1];\\n          }\\n          // Prevent big images from loading when they aren\\'t needed.\\n          // This must be done as a pre-injection step, since image loading can\\'t be\\n          // canceled once embedded into the DOM.\\n          if (self.isListPage && self.isMobile) {\\n            data = data.replace(/<(img|iframe) .+?>/g, \\'\\');\\n          }\\n          // Insert template to be rendered as nodes.\\n          content.innerHTML = data;\\n          if (self.isListPage) {\\n            var summary = document.createElement(\\'div\\');\\n            $(summary).addClass(\\'post-content\\');\\n            $(summary).addClass(\\'post-summary\\');\\n            body.insertBefore(summary, content);\\n            if (match) {\\n              // Use provided summary.\\n              summary.innerHTML = match[2];\\n            } else {\\n              // Generate a summary.\\n              // Summary generation relies on DOM, so it must occur after content is\\n              // inserted into the page.\\n              summary.innerHTML = self.generateSummaryFromContent(content, 30);\\n            }\\n            // Add read more link to summary.\\n            var titleAnchor = $(this).find(\\'.title a\\')[0];\\n            var link = titleAnchor.cloneNode(true);\\n            link.innerHTML = \\'Read More\\';\\n            $(link).addClass(\\'read-more\\');\\n            summary.appendChild(link);\\n          }\\n        });\\n        // Firefox does not allow for proper styling of BR.\\n        if (navigator.userAgent.indexOf(\\'Firefox\\') > -1) {\\n          $(\\'.post-content br\\').replaceWith(\\'<span class=\"space\"></span>\\');\\n        }\\n        $(\\'.loading\\').removeClass(\\'loading\\');\\n      };\\n      BreakpointHandler.prototype.process = function() {\\n        if (!this.initted) {\\n          var makeInsecureImageRegex = function(hosts) {\\n            var whitelist = hosts.join(\\'|\\').replace(/\\\\./g,\\'\\\\\\\\.\\');\\n            // Normal image tags, plus input images (yes, this is possible!)\\n            return new RegExp(\\'(<(img|input)[^>]+?src=(\"|\\\\\\'))http:\\\\/\\\\/(\\' + whitelist +\\')\\', \\'g\\');\\n          };\\n          this.sslImageRegex = makeInsecureImageRegex(BreakpointHandler.KNOWN_HTTPS_HOSTS);\\n          this.sslImageCurrentDomainRegex = makeInsecureImageRegex([window.location.hostname]);\\n          this.detect();\\n          this.initContent();\\n          this.initted = true;\\n        }\\n      };\\n      BreakpointHandler.KNOWN_HTTPS_HOSTS = [\\n        \"www.google.org\",\\n        \"www.google.com\",\\n        \"services.google.com\",\\n        \"blogger.com\",\\n        \"draft.blogger.com\",\\n        \"www.blogger.com\",\\n        \"photos1.blogger.com\",\\n        \"photos2.blogger.com\",\\n        \"photos3.blogger.com\",\\n        \"blogblog.com\",\\n        \"img1.blogblog.com\",\\n        \"img2.blogblog.com\",\\n        \"www.blogblog.com\",\\n        \"www1.blogblog.com\",\\n        \"www2.blogblog.com\",\\n        \"0.bp.blogspot.com\",\\n        \"1.bp.blogspot.com\",\\n        \"2.bp.blogspot.com\",\\n        \"3.bp.blogspot.com\",\\n        \"4.bp.blogspot.com\",\\n        \"lh3.googleusercontent.com\",\\n        \"lh4.googleusercontent.com\",\\n        \"lh5.googleusercontent.com\",\\n        \"lh6.googleusercontent.com\",\\n        \"themes.googleusercontent.com\",\\n      ];\\n        BreakpointHandler.prototype.rewriteForSSL = function(html) {\\n        // Handle HTTP -> HTTPS source replacement of images, movies, and other embedded content.\\n        return html.replace(this.sslImageRegex, \\'$1https://$4\\')\\n        .replace(this.sslImageCurrentDomainRegex, \\'$1//$4\\')\\n        .replace(/(<(embed|iframe)[^>]+?src=(\"|\\'))http:\\\\/\\\\/([^\"\\']*?(youtube|picasaweb\\\\.google)\\\\.com)/g, \\'$1https://$4\\')\\n        // Slideshow SWF takes a image host, so we need to rewrite that parameter.\\n        .replace(/(<embed[^>]+?feed=http(?=[^s]))/g, \\'$1s\\');\\n        };\\n        $(document).ready(function() {\\n        var handler = new BreakpointHandler();\\n        handler.process();\\n        // Top-level navigation.\\n        $(\".BlogArchive .tab\").click(function(ev) {\\n        ev.preventDefault();\\n        $(this).parent().toggleClass(\\'active\\');\\n        $(this).siblings().slideToggle(300);\\n        });\\n        $(\".Label .tab\").click(function(ev) {\\n        ev.preventDefault();\\n        $(this).parent().toggleClass(\\'active\\');\\n        $(this).siblings().slideToggle(300);\\n        });\\n        // Blog archive year expansion.\\n        $(\\'.BlogArchive .intervalToggle\\').click(function(ev) {\\n        ev.preventDefault();\\n        if ($(this).parent().hasClass(\\'collapsed\\')) {\\n        $(this).parent().removeClass(\\'collapsed\\');\\n        $(this).parent().addClass(\\'expanded\\');\\n        } else {\\n        $(this).parent().removeClass(\\'expanded\\');\\n        $(this).parent().addClass(\\'collapsed\\');\\n        }\\n        });\\n        // Reverse order of months.\\n        $(\\'.BlogArchive .intervalToggle + div\\').each(function(_, items) {\\n        var year = $(this);\\n        year.children().each(function(_, month) {\\n        year.prepend(month);\\n        });\\n        });\\n        // Set anchors to open in new tab.\\n        $(\\'.post-content img\\').parent().each(function(_, node) {\\n        if (node.nodeName == \\'A\\') {\\n        $(this).attr(\\'target\\', \\'_blank\\');\\n        }\\n        });\\n        // Process search requests.\\n        $(\\'.searchBox input\\').on(\"keypress\", function(ev) {\\n        if (ev.which == 13) {\\n        window.location.href = \\'https://www.google.com/search?q=site%3A\\' + window.location.hostname + \\'%20\\' + encodeURIComponent ($(this).val());\\n        }\\n        });\\n        });\\n        //]]>\\n    \\n\\n\\n\\n\\n        document.addEventListener(\\'DOMContentLoaded\\',function() {\\n            prettyPrint();\\n        });\\n    \\n\\n\\n\\nwindow[\\'__wavt\\'] = \\'AOuZoY5F_3cYWFPgPdI68cS9iEoviA5k5Q:1527773807438\\';_WidgetManager._Init(\\'//www.blogger.com/rearrange?blogID\\\\x3d8474926331452026626\\',\\'//ai.googleblog.com/2018/01/the-google-brain-team-looking-back-on_12.html\\',\\'8474926331452026626\\');\\n_WidgetManager._SetDataContext([{\\'name\\': \\'blog\\', \\'data\\': {\\'blogId\\': \\'8474926331452026626\\', \\'title\\': \\'Google AI Blog\\', \\'url\\': \\'http://ai.googleblog.com/2018/01/the-google-brain-team-looking-back-on_12.html\\', \\'canonicalUrl\\': \\'http://ai.googleblog.com/2018/01/the-google-brain-team-looking-back-on_12.html\\', \\'homepageUrl\\': \\'http://ai.googleblog.com/\\', \\'searchUrl\\': \\'http://ai.googleblog.com/search\\', \\'canonicalHomepageUrl\\': \\'http://ai.googleblog.com/\\', \\'blogspotFaviconUrl\\': \\'http://ai.googleblog.com/favicon.ico\\', \\'bloggerUrl\\': \\'https://www.blogger.com\\', \\'hasCustomDomain\\': true, \\'httpsEnabled\\': false, \\'enabledCommentProfileImages\\': true, \\'gPlusViewType\\': \\'FILTERED_POSTMOD\\', \\'adultContent\\': false, \\'analyticsAccountNumber\\': \\'UA-961555-69\\', \\'encoding\\': \\'UTF-8\\', \\'locale\\': \\'en\\', \\'localeUnderscoreDelimited\\': \\'en\\', \\'languageDirection\\': \\'ltr\\', \\'isPrivate\\': false, \\'isMobile\\': false, \\'isMobileRequest\\': false, \\'mobileClass\\': \\'\\', \\'isPrivateBlog\\': false, \\'feedLinks\\': \\'\\\\x3clink rel\\\\x3d\\\\x22alternate\\\\x22 type\\\\x3d\\\\x22application/atom+xml\\\\x22 title\\\\x3d\\\\x22Google AI Blog - Atom\\\\x22 href\\\\x3d\\\\x22http://ai.googleblog.com/feeds/posts/default\\\\x22 /\\\\x3e\\\\n\\\\x3clink rel\\\\x3d\\\\x22alternate\\\\x22 type\\\\x3d\\\\x22application/rss+xml\\\\x22 title\\\\x3d\\\\x22Google AI Blog - RSS\\\\x22 href\\\\x3d\\\\x22http://ai.googleblog.com/feeds/posts/default?alt\\\\x3drss\\\\x22 /\\\\x3e\\\\n\\\\x3clink rel\\\\x3d\\\\x22service.post\\\\x22 type\\\\x3d\\\\x22application/atom+xml\\\\x22 title\\\\x3d\\\\x22Google AI Blog - Atom\\\\x22 href\\\\x3d\\\\x22https://www.blogger.com/feeds/8474926331452026626/posts/default\\\\x22 /\\\\x3e\\\\n\\\\n\\\\x3clink rel\\\\x3d\\\\x22alternate\\\\x22 type\\\\x3d\\\\x22application/atom+xml\\\\x22 title\\\\x3d\\\\x22Google AI Blog - Atom\\\\x22 href\\\\x3d\\\\x22http://ai.googleblog.com/feeds/4926398674824983330/comments/default\\\\x22 /\\\\x3e\\\\n\\', \\'meTag\\': \\'\\', \\'openIdOpTag\\': \\'\\', \\'adsenseHostId\\': \\'ca-host-pub-1556223355139109\\', \\'adsenseHasAds\\': false, \\'ieCssRetrofitLinks\\': \\'\\\\x3c!--[if IE]\\\\x3e\\\\x3cscript type\\\\x3d\\\\x22text/javascript\\\\x22 src\\\\x3d\\\\x22https://www.blogger.com/static/v1/jsbin/3658603751-ieretrofit.js\\\\x22\\\\x3e\\\\x3c/script\\\\x3e\\\\n\\\\x3c![endif]--\\\\x3e\\', \\'view\\': \\'\\', \\'dynamicViewsCommentsSrc\\': \\'//www.blogblog.com/dynamicviews/4224c15c4e7c9321/js/comments.js\\', \\'dynamicViewsScriptSrc\\': \\'//www.blogblog.com/dynamicviews/b033e84ab8d80e51\\', \\'plusOneApiSrc\\': \\'https://apis.google.com/js/plusone.js\\', \\'sharing\\': {\\'platforms\\': [{\\'name\\': \\'Get link\\', \\'key\\': \\'link\\', \\'shareMessage\\': \\'Get link\\', \\'target\\': \\'\\'}, {\\'name\\': \\'Facebook\\', \\'key\\': \\'facebook\\', \\'shareMessage\\': \\'Share to Facebook\\', \\'target\\': \\'facebook\\'}, {\\'name\\': \\'BlogThis!\\', \\'key\\': \\'blogThis\\', \\'shareMessage\\': \\'BlogThis!\\', \\'target\\': \\'blog\\'}, {\\'name\\': \\'Twitter\\', \\'key\\': \\'twitter\\', \\'shareMessage\\': \\'Share to Twitter\\', \\'target\\': \\'twitter\\'}, {\\'name\\': \\'Pinterest\\', \\'key\\': \\'pinterest\\', \\'shareMessage\\': \\'Share to Pinterest\\', \\'target\\': \\'pinterest\\'}, {\\'name\\': \\'Google+\\', \\'key\\': \\'googlePlus\\', \\'shareMessage\\': \\'Share to Google+\\', \\'target\\': \\'googleplus\\'}, {\\'name\\': \\'Email\\', \\'key\\': \\'email\\', \\'shareMessage\\': \\'Email\\', \\'target\\': \\'email\\'}], \\'googlePlusShareButtonWidth\\': 300, \\'googlePlusBootstrap\\': \\'\\\\x3cscript type\\\\x3d\\\\x22text/javascript\\\\x22\\\\x3ewindow.___gcfg \\\\x3d {\\\\x27lang\\\\x27: \\\\x27en\\\\x27};\\\\x3c/script\\\\x3e\\'}, \\'hasCustomJumpLinkMessage\\': false, \\'jumpLinkMessage\\': \\'Read more\\', \\'pageType\\': \\'item\\', \\'postId\\': \\'4926398674824983330\\', \\'postImageThumbnailUrl\\': \\'https://1.bp.blogspot.com/-TrFdtDyPH-0/Wlf4L-Mk0CI/AAAAAAAACVE/h1DHy_qepI0iGydt_Lc2sM69OQxr3RVHACLcBGAs/s72-c/image2.png\\', \\'postImageUrl\\': \\'https://1.bp.blogspot.com/-TrFdtDyPH-0/Wlf4L-Mk0CI/AAAAAAAACVE/h1DHy_qepI0iGydt_Lc2sM69OQxr3RVHACLcBGAs/s640/image2.png\\', \\'pageName\\': \\'The Google Brain Team &#8212; Looking Back on 2017 (Part 2 of 2)\\', \\'pageTitle\\': \\'Google AI Blog: The Google Brain Team &#8212; Looking Back on 2017 (Part 2 of 2)\\'}}, {\\'name\\': \\'features\\', \\'data\\': {\\'lazy_images\\': \\'false\\', \\'poll_static\\': \\'true\\', \\'sharing_get_link_dialog\\': \\'true\\', \\'sharing_native\\': \\'false\\'}}, {\\'name\\': \\'messages\\', \\'data\\': {\\'edit\\': \\'Edit\\', \\'linkCopiedToClipboard\\': \\'Link copied to clipboard!\\', \\'ok\\': \\'Ok\\', \\'postLink\\': \\'Post Link\\'}}, {\\'name\\': \\'template\\', \\'data\\': {\\'name\\': \\'custom\\', \\'localizedName\\': \\'Custom\\', \\'isResponsive\\': false, \\'isAlternateRendering\\': false, \\'isCustom\\': true}}, {\\'name\\': \\'view\\', \\'data\\': {\\'classic\\': {\\'name\\': \\'classic\\', \\'url\\': \\'?view\\\\x3dclassic\\'}, \\'flipcard\\': {\\'name\\': \\'flipcard\\', \\'url\\': \\'?view\\\\x3dflipcard\\'}, \\'magazine\\': {\\'name\\': \\'magazine\\', \\'url\\': \\'?view\\\\x3dmagazine\\'}, \\'mosaic\\': {\\'name\\': \\'mosaic\\', \\'url\\': \\'?view\\\\x3dmosaic\\'}, \\'sidebar\\': {\\'name\\': \\'sidebar\\', \\'url\\': \\'?view\\\\x3dsidebar\\'}, \\'snapshot\\': {\\'name\\': \\'snapshot\\', \\'url\\': \\'?view\\\\x3dsnapshot\\'}, \\'timeslide\\': {\\'name\\': \\'timeslide\\', \\'url\\': \\'?view\\\\x3dtimeslide\\'}, \\'isMobile\\': false, \\'title\\': \\'The Google Brain Team &#8212; Looking Back on 2017 (Part 2 of 2)\\', \\'description\\': \\'Posted by Jeff Dean, Google Senior Fellow, on behalf of the entire Google Brain Team   The Google Brain team  works to advance the state of ...\\', \\'featuredImage\\': \\'https://1.bp.blogspot.com/-TrFdtDyPH-0/Wlf4L-Mk0CI/AAAAAAAACVE/h1DHy_qepI0iGydt_Lc2sM69OQxr3RVHACLcBGAs/s640/image2.png\\', \\'url\\': \\'http://ai.googleblog.com/2018/01/the-google-brain-team-looking-back-on_12.html\\', \\'type\\': \\'item\\', \\'isSingleItem\\': true, \\'isMultipleItems\\': false, \\'isError\\': false, \\'isPage\\': false, \\'isPost\\': true, \\'isHomepage\\': false, \\'isArchive\\': false, \\'isLabelSearch\\': false, \\'postId\\': 4926398674824983330}}]);\\n_WidgetManager._RegisterWidget(\\'_HeaderView\\', new _WidgetInfo(\\'Header1\\', \\'header\\', null, document.getElementById(\\'Header1\\'), {}, \\'displayModeFull\\'));\\n_WidgetManager._RegisterWidget(\\'_BlogView\\', new _WidgetInfo(\\'Blog1\\', \\'main\\', null, document.getElementById(\\'Blog1\\'), {\\'cmtInteractionsEnabled\\': false, \\'legacyCommentModerationUrl\\': \\'https://www.blogger.com/moderate-legacy-comment.g?blogID\\\\x3d8474926331452026626\\', \\'iframeCommentsId\\': \\'gpluscomments\\', \\'viewType\\': \\'FILTERED_POSTMOD\\', \\'useNgc\\': false}, \\'displayModeFull\\'));\\n_WidgetManager._RegisterWidget(\\'_HTMLView\\', new _WidgetInfo(\\'HTML8\\', \\'sidebar-top\\', null, document.getElementById(\\'HTML8\\'), {}, \\'displayModeFull\\'));\\n_WidgetManager._RegisterWidget(\\'_LabelView\\', new _WidgetInfo(\\'Label1\\', \\'sidebar\\', null, document.getElementById(\\'Label1\\'), {}, \\'displayModeFull\\'));\\n_WidgetManager._RegisterWidget(\\'_BlogArchiveView\\', new _WidgetInfo(\\'BlogArchive1\\', \\'sidebar\\', null, document.getElementById(\\'BlogArchive1\\'), {\\'languageDirection\\': \\'ltr\\', \\'loadingMessage\\': \\'Loading\\\\x26hellip;\\'}, \\'displayModeFull\\'));\\n_WidgetManager._RegisterWidget(\\'_HTMLView\\', new _WidgetInfo(\\'HTML6\\', \\'sidebar\\', null, document.getElementById(\\'HTML6\\'), {}, \\'displayModeFull\\'));\\n_WidgetManager._RegisterWidget(\\'_HTMLView\\', new _WidgetInfo(\\'HTML5\\', \\'sidebar-bottom\\', null, document.getElementById(\\'HTML5\\'), {}, \\'displayModeFull\\'));\\n_WidgetManager._RegisterWidget(\\'_HTMLView\\', new _WidgetInfo(\\'HTML1\\', \\'sidebar-bottom\\', null, document.getElementById(\\'HTML1\\'), {}, \\'displayModeFull\\'));\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://ai.googleblog.com/2018/01/the-google-brain-team-looking-back-on_12.html'\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "soup.body.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
