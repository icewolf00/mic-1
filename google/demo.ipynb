{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://ai.googleblog.com/2018/01/the-google-brain-team-looking-back-on_12.html'\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "body = soup.body.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = body.replace('\\n', '')\n",
    "# body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = body[:body.index('Thanks for reading!')]\n",
    "# body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('a'):\n",
    "    body = body.replace(str(i), '')\n",
    "# body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('iframe'):\n",
    "    body = body.replace(str(i), '')\n",
    "# body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('div'):\n",
    "    body = body.replace(str(i), '')\n",
    "# body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('td'):\n",
    "    body = body.replace(str(i), '')\n",
    "# body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'      //<![CDATA[      var axel = Math.random() + \"\";      var a = axel * 10000000000000;      document.write(\\'<iframe src=\"https://2542116.fls.doubleclick.net/activityi;src=2542116;type=gblog;cat=googl0;ord=ord=\\' + a + \\'?\" width=\"1\" height=\"1\" frameborder=\"0\" style=\"display:none\"></iframe>\\');      //]]>                Blog          The latest news from Google AIThe Google Brain Team — Looking Back on 2017 (Part 2 of 2)Friday, January 12, 2018                          <span class=\"byline-author\">Posted by Jeff Dean, Google Senior Fellow, on behalf of the entire Google Brain Team</span><br /><br />The  works to advance the state of the art in artificial intelligence by research and systems engineering, as one part of the overall  effort.  In , we shared some of our work in 2017 related to our broader research, from designing new machine learning algorithms and techniques to understanding them, as well as sharing data, software, and hardware with the community. In this post, we&#8217;ll dive into the research we do in some specific domains such as healthcare, robotics, creativity, fairness and inclusion, as well as share a little more about us.<br /><br /><b>Healthcare</b><br />We feel there is enormous potential for the application of machine learning techniques to healthcare.  We are doing work across many different kinds of problems, including ,  to assist doctors and patients, and using machine learning to tackle a wide variety of problems in genomics, including an open-source release of a .  <br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://research.googleblog.com/2017/03/assisting-pathologists-in-detecting.html\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"812\" data-original-width=\"1326\" height=\"390\" src=\"https://1.bp.blogspot.com/-TrFdtDyPH-0/Wlf4L-Mk0CI/AAAAAAAACVE/h1DHy_qepI0iGydt_Lc2sM69OQxr3RVHACLcBGAs/s640/image2.png\" width=\"640\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">A lymph node biopsy, where  and not the benign macrophage.</td></tr></tbody></table>We have continued our work on early detection of diabetic retinopathy (DR) and macular edema, building on the  we published December 2016 in the Journal of the American Medical Association ().  In 2017, we moved this project from research project to actual clinical impact.  We partnered with  (a life sciences company within Alphabet) to guide this work through the regulatory process, and together we are incorporating this technology into .  In addition, we are working to deploy this system in India, where there is a shortage of 127,000 eye doctors and as a result, almost half of patients are diagnosed too late &#8212; after the disease has already caused vision loss. As a part of a pilot, we&#8217;ve launched this system to help graders at  to better diagnose diabetic eye disease. We are also working with our partners to understand the human factors affecting diabetic eye care, from ethnographic studies of patients and healthcare providers, to investigations on how eye care clinicians interact with the AI-enabled system.<br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://2.bp.blogspot.com/-TJ_QlzQ0hhs/Wlf4nReumNI/AAAAAAAACVI/BcQiAQ_2sI4Az4-v767a4pT9VNU6KN6xQCLcBGAs/s1600/2.png\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"825\" data-original-width=\"655\" height=\"640\" src=\"https://2.bp.blogspot.com/-TJ_QlzQ0hhs/Wlf4nReumNI/AAAAAAAACVI/BcQiAQ_2sI4Az4-v767a4pT9VNU6KN6xQCLcBGAs/s640/2.png\" width=\"507\" /></a></td></tr><tr></tr></tbody></table>We have also teamed up with researchers at leading healthcare organizations and medical centers including , , and  to demonstrate the effectiveness of using  (i.e. given the current state of a patient, we believe we can predict the future for a patient by learning from millions of other patients&#8217; journeys, as a way of helping healthcare professionals make better decisions).  We&#8217;re very excited about this avenue of work and we look to forward to telling you more about it in 2018. <br /><br /><b>Robotics</b><br />Our long-term goal in robotics is to design learning algorithms to allow robots to operate in messy, real-world environments and to quickly acquire new skills and capabilities via learning, rather than the carefully-controlled conditions and the small set of hand-programmed tasks that characterize today&#8217;s robots. One thrust of our research is on developing techniques for physical robots to use their own experience and those of other robots to build new skills and capabilities, pooling the shared experiences in order to learn collectively.  We are also exploring ways in which we can combine  to learn new tasks more rapidly.  While the physics of the simulator don&#8217;t entirely match up with the real world, we have observed that for robotics, simulated experience plus a small amount of real-world experience gives significantly better results than even large amounts of real-world experience on its own.<br /><br />In addition to real-world robotic experience and simulated robotic environments, we have  of desired behaviors, and believe that this imitation learning approach is a highly promising way of imparting new abilities to robots very quickly, without explicit programming or even explicit specification of the goal of an activity.  For example, below is a video of a robot learning to pour from a cup in just 15 minutes of real world experience by observing humans performing this task from different viewpoints and then trying to imitate the behavior.  As we might be with our own three-year-old child, we&#8217;re encouraged that it only spills a little!<br /><div class=\"separator\" style=\"clear: both; text-align: center;\"></div><br />We also co-organized and hosted the first occurrence of the new  (CoRL) in November to bring together researchers working at the intersection of machine learning and robotics. The  contains more information, and we look forward to next year&#8217;s occurrence of the conference in Zürich.<br /><br /><b>Basic Science</b><br />We are also excited about the long term potential of using machine learning to help solve important problems in science. Last year, we utilized neural networks for  in quantum chemistry,  in astronomical datasets, earthquake aftershock prediction, and used .<br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://arxiv.org/abs/1704.01212\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"235\" data-original-width=\"389\" height=\"241\" src=\"https://2.bp.blogspot.com/-O-fwquqFsgg/Wlf5EMe0A2I/AAAAAAAACVU/u-HSdvnWYbwhR7GJcTwLsE7IpdcuzWJbgCLcBGAs/s400/image1.png\" width=\"400\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"></td></tr></tbody></table><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://www.blog.google/topics/machine-learning/hunting-planets-machine-learning/\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"449\" data-original-width=\"904\" height=\"197\" src=\"https://3.bp.blogspot.com/-3Sv9BduvARE/Wlf5YBWvnzI/AAAAAAAACVY/8ypa7bIEPFUdcSS8uNfDi5Zrd8hATuf9gCLcBGAs/s400/image9.png\" width=\"400\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">: observing brightness of stars when planets block their light.&nbsp;</td></tr></tbody></table><b>Creativity</b><br />We&#8217;re very interested in how to leverage machine learning as a tool to assist people in creative endeavors.  This year, we created an , helped YouTube musician Andrew Huang  (see also the behind the scenes video with ), and showed .  <br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"360\" data-original-width=\"640\" height=\"360\" src=\"https://1.bp.blogspot.com/-Z3R4BkRw8qg/Wlf5wUmckII/AAAAAAAACVg/PU5D0MsR_tY8YKyr00sHMGrxlrjErtg1wCLcBGAs/s640/image3.gif\" width=\"640\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">A garden drawn by the ; an interactive demo is .</td></tr></tbody></table>We also demonstrated . This work won the , making this the second year in a row that members of the Brain team&#8217;s  have won this award, following on our receipt of the  for . In the YouTube video below, you can listen to one part of the demo, the  variational autoencoder model morphing smoothly from one melody to another. <br /><div class=\"separator\" style=\"clear: both; text-align: center;\"></div><b>People + AI Research (PAIR) Initiative</b><br />Advances in machine learning offer entirely new possibilities for how people might interact with computers.  At the same time, it&#8217;s critical to make sure that society can broadly benefit from the technology we&#8217;re building.  We see these opportunities and challenges as an urgent matter, and teamed up with a number of people throughout Google to create the  initiative.<br /><br />PAIR&#8217;s goal is to study and design the most effective ways for people to interact with AI systems.  We kicked off the initiative with a  bringing together academics and practitioners across disciplines ranging from computer science, design, and even art.  PAIR works on a wide range of topics, some of which we&#8217;ve already mentioned: helping researchers understand ML systems through work on interpretability and expanding the community of developers with .  Another example of our human-centered approach to ML engineering is the launch of , a tool for visualizing and understanding training datasets.<br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://pair-code.github.io/facets/\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"505\" data-original-width=\"620\" height=\"520\" src=\"https://1.bp.blogspot.com/-okXsVBEhLws/Wlf6S3qliHI/AAAAAAAACVs/ddGvwr3jKLw9bTuUqlDuiu2Z4k_ABPQjgCLcBGAs/s640/image4.gif\" width=\"640\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"> provides insights into your training datasets.</td></tr></tbody></table><b>Fairness and Inclusion in Machine Learning</b><br />As ML plays an increasing role in technology, considerations of inclusivity and fairness grow in importance. The Brain team and  have been working hard to make progress in these areas. We&#8217;ve published on  via causal reasoning, the importance of , and posted .  We&#8217;ve also been working closely with the , a cross-industry initiative, to help make sure that fairness and inclusion are promoted as goals for all ML practitioners.<br /><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://4.bp.blogspot.com/-YXh56TsSCTA/WljlmZLVg9I/AAAAAAAACV8/TbYNJUZ0QfMg_7qyKni3u-HjJ18qyA69ACLcBGAs/s1600/fig.png\" imageanchor=\"1\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" data-original-height=\"1002\" data-original-width=\"1600\" height=\"400\" src=\"https://4.bp.blogspot.com/-YXh56TsSCTA/WljlmZLVg9I/AAAAAAAACV8/TbYNJUZ0QfMg_7qyKni3u-HjJ18qyA69ACLcBGAs/s640/fig.png\" width=\"640\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><br /> can surface in training data even in objects as &#8220;universal&#8221; as chairs, as observed in these doodle patterns on the left. The chart on the right shows how we uncovered  in standard open source data sets such as ImageNet. Undetected or uncorrected, such biases may strongly influence model behavior.</td></tr></tbody></table>We made this video in collaboration with our colleagues at Google Creative Lab as a non-technical introduction to some of the issues in this area.<br /><div class=\"separator\" style=\"clear: both; text-align: center;\"></div><b>Our Culture</b><br />One aspect of our group&#8217;s research culture is to empower researchers and engineers to tackle the basic research problems that they view as most important.  In September, .  Educating and mentoring young researchers is something we do through our research efforts.  Our group hosted over 100 interns last year, and roughly 25% of our research publications in 2017 have intern co-authors.  In 2016, we started the Google Brain Residency, a program for mentoring people who wanted to learn to do machine learning research.  In the inaugural year (June 2016 to May 2017), 27 residents joined our group, and we posted updates about the first year of the program in  and  highlighting the research accomplishments of the residents.  Many of the residents in the first year of the program have stayed on in our group as full-time researchers and research engineers, and most of those that did not have gone on to Ph.D. programs at top machine learning graduate programs like Berkeley, CMU, Stanford, NYU and Toronto.  In July, 2017, we also welcomed our second cohort of 35 residents, who will be with us until July, 2018, and they&#8217;ve  and .  We&#8217;ve now broadened the program to include many other research groups across Google and renamed it the  (the application deadline for this year\\'s program has just passed; look for information about next year\\'s program at ).<br /><br />Our work in 2017 spanned more than we&#8217;ve highlighted on in this two-part blog post.  We believe in publishing our work in top research venues, and last year our group published 140 papers, including more than 60 at , , and .  To learn more about our work, you can peruse our .  <br /><br />You can also meet some of our team members in this , or read our responses to our second  post on  (and check out the <a href=\"https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/\">2016&#8217;s AMA</a>, too).<br /><br />The Google Brain team is becoming more spread out, with team members across North America and Europe.  If the work we&#8217;re doing sounds interesting and you&#8217;d like to join us, you can see our open positions and apply for internships, the AI Residency program, visiting faculty, or full-time research or engineering roles using the links at the bottom of . You can also follow our work throughout 2018 here on the Google Research blog, or on Twitter at .  You can also follow my personal account at .<br /><br />'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup.find_all('img'):\n",
    "    body = body.replace(str(i), '')\n",
    "for i in soup.find_all('table'):\n",
    "    body = body.replace(str(i), '')\n",
    "for i in soup.find_all('class'):\n",
    "    body = body.replace(str(i), '')\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
